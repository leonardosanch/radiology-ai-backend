#!/usr/bin/env python3
"""
Main.py - Sistema de Radiolog√≠a IA con Arquitectura Desacoplada
==============================================================

Sistema backend avanzado que soporta m√∫ltiples modelos de IA m√©dica
con router inteligente y arquitectura escalable.

Caracter√≠sticas:
- Router inteligente para m√∫ltiples modelos
- Arquitectura completamente desacoplada
- Escalabilidad autom√°tica para nuevos modelos
- Ensemble optimizado por especializaci√≥n
- API RESTful para integraci√≥n con Liferay
"""

from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import JSONResponse
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.middleware.gzip import GZipMiddleware
import logging
import sys
import time
import traceback
from contextlib import asynccontextmanager
from typing import Dict, Any, Optional
import uvicorn
from pathlib import Path

# Importar componentes de la aplicaci√≥n
from .core.config import settings
from .core.cors import setup_cors
from .api.endpoints.analysis import router as analysis_router

# Importar sistema de IA avanzado
from .models.router.intelligent_router import AdvancedMedicalAIManager

# Configurar logging global de la aplicaci√≥n
logging.basicConfig(
    level=getattr(logging, settings.log_level.upper()),
    format=settings.log_format,
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(
            settings.logs_dir + "/" + settings.log_file,
            mode="a",
            encoding="utf-8"
        )
    ]
)

# Logger espec√≠fico para este m√≥dulo
logger = logging.getLogger(__name__)

# ============================================================================
# GESTOR GLOBAL DEL SISTEMA IA
# ============================================================================

# Instancia global del sistema IA avanzado
ai_system: Optional[AdvancedMedicalAIManager] = None

def get_ai_system() -> AdvancedMedicalAIManager:
    """
    Obtiene la instancia global del sistema IA.
    
    Returns:
        AdvancedMedicalAIManager: Sistema IA inicializado
        
    Raises:
        RuntimeError: Si el sistema no est√° inicializado
    """
    global ai_system
    if ai_system is None or not ai_system.is_initialized:
        raise RuntimeError("Sistema IA no inicializado")
    return ai_system

def initialize_ai_system() -> bool:
    """
    Inicializa el sistema IA avanzado.
    
    Returns:
        bool: True si la inicializaci√≥n fue exitosa
    """
    global ai_system
    
    try:
        logger.info("üöÄ Inicializando Sistema IA M√©dica Avanzado...")
        
        # Crear manager avanzado
        ai_system = AdvancedMedicalAIManager(
            model_path=settings.model_path,
            device=settings.device
        )
        
        # Cargar todos los modelos disponibles
        success = ai_system.load_model("intelligent_router")
        
        if success:
            # Obtener informaci√≥n del sistema inicializado
            system_info = ai_system.get_model_info()
            logger.info(f"‚úÖ Sistema IA inicializado:")
            logger.info(f"   ‚Ä¢ Tipo: {system_info.get('system_type', 'Unknown')}")
            logger.info(f"   ‚Ä¢ Modelos cargados: {system_info.get('loaded_models', 0)}")
            logger.info(f"   ‚Ä¢ Modelos activos: {', '.join(system_info.get('loaded_model_names', []))}")
            logger.info(f"   ‚Ä¢ Dispositivo: {system_info.get('device', 'Unknown')}")
            
            # Mostrar capacidades avanzadas
            capabilities = system_info.get('capabilities', {})
            logger.info("üéØ Capacidades avanzadas:")
            for capability, enabled in capabilities.items():
                status = "‚úÖ" if enabled else "‚ùå"
                logger.info(f"   ‚Ä¢ {capability}: {status}")
                
            logger.info("üè• Sistema listo para an√°lisis m√©dico avanzado")
            return True
        else:
            logger.error("‚ùå Fall√≥ la inicializaci√≥n del sistema IA")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Error cr√≠tico inicializando sistema IA: {str(e)}")
        logger.error(traceback.format_exc())
        ai_system = None
        return False

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Gesti√≥n del ciclo de vida de la aplicaci√≥n FastAPI con sistema IA avanzado.
    
    Args:
        app: Instancia de la aplicaci√≥n FastAPI
    """
    # =========================================================================
    # STARTUP - Inicializaci√≥n de la aplicaci√≥n
    # =========================================================================
    startup_time = time.time()
    logger.info("=" * 80)
    logger.info("üöÄ INICIANDO RADIOLOGY AI BACKEND API - SISTEMA AVANZADO")
    logger.info("=" * 80)
    
    try:
        # Mostrar informaci√≥n de configuraci√≥n
        logger.info(f"üìã Configuraci√≥n del sistema:")
        logger.info(f"   ‚Ä¢ Modo: {'üîß Desarrollo' if settings.debug else 'üè≠ Producci√≥n'}")
        logger.info(f"   ‚Ä¢ Host: {settings.host}:{settings.port}")
        logger.info(f"   ‚Ä¢ Dispositivo IA: {settings.device}")
        logger.info(f"   ‚Ä¢ Arquitectura: Desacoplada + Router Inteligente")
        logger.info(f"   ‚Ä¢ Tama√±o m√°ximo archivo: {settings.max_file_size / (1024*1024):.1f}MB")
        
        # Verificar directorios cr√≠ticos
        logger.info(f"üìÅ Verificando directorios:")
        for directory_name, directory_path in [
            ("Modelos", settings.model_path),
            ("Uploads", settings.upload_dir),
            ("Logs", settings.logs_dir),
            ("Cache", settings.cache_dir)
        ]:
            Path(directory_path).mkdir(parents=True, exist_ok=True)
            logger.info(f"   ‚Ä¢ {directory_name}: {directory_path} ‚úÖ")
        
        # Mostrar informaci√≥n del sistema
        system_info = settings.get_system_info()
        logger.info(f"üíª Informaci√≥n del sistema:")
        logger.info(f"   ‚Ä¢ Python: {system_info['python_version']}")
        logger.info(f"   ‚Ä¢ PyTorch: {system_info['torch_version']}")
        logger.info(f"   ‚Ä¢ CUDA disponible: {'‚úÖ' if system_info['cuda_available'] else '‚ùå'}")
        logger.info(f"   ‚Ä¢ Plataforma: {system_info['platform']}")
        
        # Mostrar configuraci√≥n de CORS para Liferay
        logger.info(f"üåê Configuraci√≥n CORS para Liferay:")
        for origin in settings.cors_origins[:3]:  # Mostrar solo los primeros 3
            logger.info(f"   ‚Ä¢ {origin}")
        if len(settings.cors_origins) > 3:
            logger.info(f"   ‚Ä¢ ... y {len(settings.cors_origins) - 3} m√°s")
        
        # Inicializar sistema IA avanzado
        logger.info("üß† Inicializando sistema de IA m√©dica...")
        
        ai_init_success = initialize_ai_system()
        
        if not ai_init_success:
            logger.error("‚ùå FALLO CR√çTICO: No se pudo inicializar el sistema IA")
            logger.error("üí° La API funcionar√° pero sin capacidades de an√°lisis")
        
        startup_duration = time.time() - startup_time
        logger.info(f"‚úÖ Inicializaci√≥n completada en {startup_duration:.2f} segundos")
        
        if ai_init_success:
            logger.info("üè• API BACKEND CON IA AVANZADA LISTA PARA LIFERAY")
        else:
            logger.warning("‚ö†Ô∏è API BACKEND EN MODO LIMITADO (SIN IA)")
            
        logger.info("=" * 80)
        
    except Exception as e:
        logger.error(f"‚ùå Error cr√≠tico durante inicializaci√≥n: {str(e)}")
        logger.error(traceback.format_exc())
        raise
    
    # Punto de yield - la aplicaci√≥n est√° corriendo
    yield
    
    # =========================================================================
    # SHUTDOWN - Cierre limpio de la aplicaci√≥n
    # =========================================================================
    logger.info("=" * 80)
    logger.info("üõë CERRANDO RADIOLOGY AI BACKEND API - SISTEMA AVANZADO")
    logger.info("=" * 80)
    
    try:
        # Limpiar recursos del sistema IA
        global ai_system
        if ai_system:
            logger.info("üßπ Limpiando recursos del sistema IA...")
            # Aqu√≠ se pueden agregar operaciones de limpieza espec√≠ficas
            ai_system = None
        
        logger.info("‚úÖ Cierre limpio completado")
        
    except Exception as e:
        logger.error(f"‚ùå Error durante cierre: {str(e)}")
    
    logger.info("üëã RADIOLOGY AI BACKEND API FINALIZADO")
    logger.info("=" * 80)

# ============================================================================
# CREAR APLICACI√ìN FASTAPI PARA BACKEND API AVANZADO
# ============================================================================

app = FastAPI(
    title="Radiology AI Backend API - Sistema Avanzado",
    description="""
    **API Backend Avanzado para An√°lisis Radiol√≥gico con Inteligencia Artificial**
    
    Sistema de nueva generaci√≥n con router inteligente y ensemble de m√∫ltiples modelos
    de IA m√©dica para an√°lisis radiol√≥gico de m√°xima precisi√≥n.
    
    ## üß† Sistema IA Avanzado
    
    - **Router Inteligente**: Selecci√≥n autom√°tica de modelos seg√∫n tipo de imagen
    - **Ensemble Multi-Modelo**: Combinaci√≥n inteligente de 4 modelos especializados
    - **An√°lisis de Consenso**: Validaci√≥n cruzada entre modelos
    - **Recomendaciones M√©dicas**: Generaci√≥n autom√°tica de recomendaciones cl√≠nicas
    
    ## üè• Modelos M√©dicos Integrados
    
    1. **ToraxModel** (TorchXRayVision) - Patolog√≠as tor√°cicas generales
    2. **FracturasModel** (MIMIC-MIT) - Detecci√≥n especializada de fracturas
    3. **CheXNetModel** (Stanford) - Especialista en neumon√≠a y t√≥rax
    4. **RadImageNetModel** (Universal) - An√°lisis m√©dico multi-modalidad
    
    ## üìä Endpoints Principales
    
    - `POST /api/v1/analysis/upload` - An√°lisis inteligente con ensemble
    - `POST /api/v1/analysis/upload?use_ensemble=false` - An√°lisis modelo √∫nico
    - `GET /api/v1/analysis/health` - Estado del sistema IA avanzado
    - `GET /api/v1/analysis/model/info` - Informaci√≥n completa del sistema
    - `GET /api/v1/analysis/models/available` - Modelos disponibles
    - `POST /api/v1/analysis/demo` - An√°lisis de demostraci√≥n avanzado
    
    ## üéØ Patolog√≠as Detectadas
    
    **Sistema combinado detecta 20+ patolog√≠as:**
    - T√≥rax: Atelectasis, Cardiomegaly, Effusion, Infiltration, Mass, Nodule, 
             Pneumonia, Pneumothorax, Consolidation, Edema, Emphysema, 
             Fibrosis, Pleural Thickening, Hernia
    - Fracturas: Simple, Complex, Displaced, Hairline, Compression, etc.
    - Universal: Abnormal findings, Inflammation, Degeneration, etc.
    
    ## üîç Capacidades Avanzadas
    
    - **An√°lisis autom√°tico de calidad de imagen**
    - **Detecci√≥n de tipo de estudio radiol√≥gico**
    - **Selecci√≥n inteligente de modelos especializados**
    - **Ensemble ponderado por confianza y especializaci√≥n**
    - **An√°lisis de consenso entre modelos**
    - **Recomendaciones m√©dicas autom√°ticas**
    - **Evaluaci√≥n de urgencia cl√≠nica**
    - **Trazabilidad completa de decisiones**
    
    ## üìÅ Formatos Soportados
    
    DICOM (.dcm), JPEG (.jpg), PNG (.png), TIFF (.tiff), BMP (.bmp)
    
    ## ‚ö° Performance
    
    - **An√°lisis ensemble**: ~2-4 segundos
    - **An√°lisis modelo √∫nico**: ~0.5-1 segundo
    - **Procesamiento paralelo** conceptual de modelos
    - **Cache inteligente** para optimizaci√≥n
    
    ‚ö†Ô∏è **Importante**: Herramienta de apoyo diagn√≥stico avanzado. 
    Requiere validaci√≥n m√©dica profesional.
    """,
    version="2.0.0",
    
    # Configuraci√≥n de documentaci√≥n
    docs_url="/docs" if settings.debug else None,
    redoc_url="/redoc" if settings.debug else None,
    openapi_url="/openapi.json" if settings.debug else None,
    
    # Gesti√≥n del ciclo de vida
    lifespan=lifespan,
    
    # Metadatos para integraci√≥n
    contact={
        "name": "Radiology AI Advanced Team",
        "email": "advanced-backend@radiologyai.com"
    },
    license_info={
        "name": "Medical AI License",
        "url": "https://radiologyai.com/license"
    },
    tags_metadata=[
        {
            "name": "analysis",
            "description": "An√°lisis radiol√≥gico avanzado con IA",
        },
        {
            "name": "health",
            "description": "Monitoreo del sistema IA",
        },
        {
            "name": "models",
            "description": "Informaci√≥n de modelos IA",
        },
    ]
)

# ============================================================================
# CONFIGURAR MIDDLEWARE PARA INTEGRACION CON LIFERAY
# ============================================================================

# Configurar CORS espec√≠ficamente para Liferay
setup_cors(app)

# Middleware de compresi√≥n para optimizar transferencia de datos
app.add_middleware(GZipMiddleware, minimum_size=1000)

# Middleware de seguridad para producci√≥n
if not settings.debug:
    app.add_middleware(
        TrustedHostMiddleware,
        allowed_hosts=["localhost", "127.0.0.1", "0.0.0.0", "*.yourdomain.com"]
    )

# ============================================================================
# MIDDLEWARE PERSONALIZADO PARA API AVANZADA
# ============================================================================

@app.middleware("http")
async def advanced_api_logging_middleware(request: Request, call_next):
    """
    Middleware para logging avanzado de API requests.
    
    Args:
        request: Request HTTP entrante
        call_next: Siguiente funci√≥n en la cadena
        
    Returns:
        Response con headers de API avanzada
    """
    start_time = time.time()
    
    # Generar ID √∫nico para el request
    request_id = f"ai_{int(start_time * 1000000) % 1000000}"
    
    # Log del request para API
    client_ip = request.client.host if request.client else "unknown"
    
    logger.info(
        f"[{request_id}] API {request.method} {request.url.path} from {client_ip}"
    )
    
    try:
        # Procesar request
        response = await call_next(request)
        
        # Calcular tiempo de procesamiento
        process_time = time.time() - start_time
        
        # Headers espec√≠ficos para API backend avanzada
        response.headers["X-Process-Time"] = str(round(process_time, 4))
        response.headers["X-Request-ID"] = request_id
        response.headers["X-API-Version"] = "v2.0"
        response.headers["X-Backend-Service"] = "radiology-ai-advanced"
        response.headers["X-AI-System"] = "intelligent-router"
        
        # Agregar informaci√≥n del sistema IA si est√° disponible
        try:
            ai_sys = get_ai_system()
            available_models = ai_sys.get_available_models()
            response.headers["X-AI-Models-Active"] = str(len(available_models))
            response.headers["X-AI-Capabilities"] = "ensemble,routing,consensus"
        except:
            response.headers["X-AI-Status"] = "unavailable"
        
        # Log de respuesta
        logger.info(
            f"[{request_id}] {response.status_code} in {process_time:.3f}s"
        )
        
        # Log especial para an√°lisis completados
        if request.url.path.endswith("/upload") and response.status_code == 200:
            logger.info(f"[{request_id}] üß† An√°lisis IA avanzado para Liferay completado")
        
        return response
        
    except Exception as e:
        process_time = time.time() - start_time
        logger.error(f"[{request_id}] API Error after {process_time:.3f}s: {str(e)}")
        raise

@app.middleware("http")
async def ai_system_middleware(request: Request, call_next):
    """
    Middleware espec√≠fico para el sistema IA avanzado.
    
    Args:
        request: Request HTTP
        call_next: Siguiente funci√≥n
        
    Returns:
        Response con informaci√≥n del sistema IA
    """
    response = await call_next(request)
    
    # Headers espec√≠ficos para sistema IA
    response.headers["X-AI-Architecture"] = "decoupled-intelligent-router"
    response.headers["X-AI-Ensemble"] = "available"
    
    # Headers de cache espec√≠ficos para an√°lisis IA
    if request.url.path.startswith("/api/v1/analysis"):
        # No cache para an√°lisis m√©dicos (siempre fresh)
        response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
        response.headers["Pragma"] = "no-cache"
        response.headers["Expires"] = "0"
    elif request.url.path.endswith("/model/info"):
        # Cache corto para info de modelos
        response.headers["Cache-Control"] = "public, max-age=300"  # 5 minutos
    
    return response

# ============================================================================
# INCLUIR ROUTERS DE API
# ============================================================================

# Router principal de an√°lisis radiol√≥gico
app.include_router(analysis_router, prefix="/api/v1", tags=["analysis"])

# ============================================================================
# ENDPOINTS B√ÅSICOS DE API AVANZADA
# ============================================================================

@app.get("/",
         summary="API Root - Sistema Avanzado",
         description="Informaci√≥n b√°sica de la API backend avanzada",
         tags=["root"])
async def api_root():
    """
    Endpoint ra√≠z de la API con informaci√≥n del sistema avanzado.
    
    Returns:
        Dict: Informaci√≥n de la API avanzada
    """
    # Obtener informaci√≥n del sistema IA si est√° disponible
    ai_info = {}
    try:
        ai_sys = get_ai_system()
        system_info = ai_sys.get_model_info()
        ai_info = {
            "ai_system_status": "operational",
            "ai_system_type": system_info.get("system_type", "Unknown"),
            "loaded_models": system_info.get("loaded_models", 0),
            "active_models": system_info.get("loaded_model_names", []),
            "ai_capabilities": list(system_info.get("capabilities", {}).keys())
        }
    except:
        ai_info = {
            "ai_system_status": "unavailable",
            "ai_system_type": "none",
            "loaded_models": 0,
            "active_models": [],
            "ai_capabilities": []
        }
    
    return {
        "service": "Radiology AI Backend API - Sistema Avanzado",
        "version": "2.0.0",
        "status": "operational",
        "mode": "development" if settings.debug else "production",
        "architecture": "decoupled_intelligent_router",
        "api_base": "/api/v1",
        "endpoints": {
            "analysis_ensemble": "/api/v1/analysis/upload",
            "analysis_single": "/api/v1/analysis/upload?use_ensemble=false",
            "health": "/api/v1/analysis/health",
            "demo": "/api/v1/analysis/demo",
            "model_info": "/api/v1/analysis/model/info",
            "available_models": "/api/v1/analysis/models/available"
        },
        "capabilities": {
            "intelligent_routing": True,
            "ensemble_analysis": True,
            "consensus_validation": True,
            "medical_recommendations": True,
            "automatic_model_selection": True,
            "image_quality_assessment": True,
            "pathologies_detected": "20+",
            "formats_supported": settings.allowed_extensions,
            "max_file_size_mb": settings.max_file_size / (1024 * 1024),
            "real_time_analysis": True,
            "liferay_integration": True
        },
        "ai_system": ai_info,
        "cors_configured": True,
        "timestamp": time.time()
    }

@app.get("/health",
         summary="Quick Health Check - Sistema Avanzado",
         description="Verificaci√≥n r√°pida de estado para monitoreo",
         tags=["health"])
async def quick_health():
    """
    Health check r√°pido para monitoreo autom√°tico del sistema avanzado.
    
    Returns:
        Dict: Estado b√°sico del sistema
    """
    # Verificar estado del sistema IA
    ai_status = "unknown"
    ai_models_count = 0
    
    try:
        ai_sys = get_ai_system()
        ai_status = "operational"
        ai_models_count = len(ai_sys.get_available_models())
    except:
        ai_status = "unavailable"
    
    health_status = "healthy" if ai_status == "operational" else "degraded"
    
    return {
        "status": health_status,
        "service": "radiology-ai-backend-advanced",
        "version": "2.0.0",
        "timestamp": time.time(),
        "uptime": True,
        "api_operational": True,
        "ai_system": {
            "status": ai_status,
            "models_loaded": ai_models_count,
            "capabilities": ["ensemble", "routing", "consensus"] if ai_status == "operational" else []
        }
    }

@app.get("/ping",
         summary="Ping Test - Sistema Avanzado",
         description="Test de conectividad simple",
         tags=["connectivity"])
async def ping():
    """
    Endpoint simple para test de conectividad desde Liferay.
    
    Returns:
        Dict: Respuesta de ping con info del sistema
    """
    return {
        "ping": "pong",
        "timestamp": time.time(),
        "service": "radiology-ai-backend-advanced",
        "architecture": "intelligent_router",
        "system_ready": True
    }

@app.get("/system/status",
         summary="Estado Completo del Sistema",
         description="Estado detallado del sistema IA y todos sus componentes",
         tags=["system"])
async def system_status():
    """
    Endpoint para obtener estado completo del sistema IA avanzado.
    
    Returns:
        Dict: Estado detallado del sistema
    """
    try:
        ai_sys = get_ai_system()
        system_info = ai_sys.get_model_info()
        
        return {
            "system_status": "operational",
            "ai_system": system_info,
            "performance": {
                "models_loaded": system_info.get("loaded_models", 0),
                "models_available": system_info.get("total_models", 0),
                "active_models": system_info.get("loaded_model_names", [])
            },
            "capabilities_status": {
                capability: "available" for capability in system_info.get("capabilities", {})
            },
            "timestamp": time.time()
        }
    except Exception as e:
        logger.error(f"Error obteniendo estado del sistema: {e}")
        return {
            "system_status": "error",
            "error": str(e),
            "ai_system": {"status": "unavailable"},
            "timestamp": time.time()
        }

# ============================================================================
# MANEJADORES DE ERRORES PARA API AVANZADA
# ============================================================================

@app.exception_handler(404)
async def advanced_api_not_found_handler(request: Request, exc):
    """
    Manejador de 404 optimizado para API avanzada.
    
    Args:
        request: Request que caus√≥ el error
        exc: Excepci√≥n 404
        
    Returns:
        JSONResponse: Error estructurado para API
    """
    logger.warning(f"API 404: {request.url.path}")
    
    return JSONResponse(
        status_code=404,
        content={
            "error": "endpoint_not_found",
            "message": f"API endpoint '{request.url.path}' not found",
            "available_endpoints": [
                "/api/v1/analysis/upload",
                "/api/v1/analysis/health",
                "/api/v1/analysis/demo", 
                "/api/v1/analysis/model/info",
                "/api/v1/analysis/models/available",
                "/health",
                "/ping",
                "/system/status"
            ],
            "api_version": "v2.0",
            "system_type": "advanced_ai",
            "timestamp": time.time()
        }
    )

@app.exception_handler(500)
async def advanced_api_internal_error_handler(request: Request, exc):
    """
    Manejador de errores internos para API avanzada.
    
    Args:
        request: Request que caus√≥ el error
        exc: Excepci√≥n interna
        
    Returns:
        JSONResponse: Error estructurado
    """
    error_id = f"ai_err_{int(time.time() * 1000) % 1000000}"
    
    logger.error(f"API Error [{error_id}] en {request.url.path}: {str(exc)}")
    logger.error(traceback.format_exc())
    
    # Verificar si es error del sistema IA
    ai_error = False
    try:
        get_ai_system()
    except:
        ai_error = True
    
    return JSONResponse(
        status_code=500,
        content={
            "error": "internal_server_error",
            "error_id": error_id,
            "message": "Internal API error occurred",
            "ai_system_error": ai_error,
            "system_type": "advanced_ai",
            "timestamp": time.time(),
            "request_path": str(request.url.path)
        }
    )

@app.exception_handler(HTTPException)
async def advanced_api_http_exception_handler(request: Request, exc: HTTPException):
    """
    Manejador de HTTPExceptions para API avanzada.
    
    Args:
        request: Request que caus√≥ la excepci√≥n
        exc: HTTPException
        
    Returns:
        JSONResponse: Error HTTP estructurado
    """
    logger.warning(f"API HTTP {exc.status_code}: {exc.detail}")
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": f"http_{exc.status_code}",
            "detail": exc.detail,
            "api_version": "v2.0",
            "system_type": "advanced_ai",
            "timestamp": time.time(),
            "path": str(request.url.path)
        }
    )

# ============================================================================
# ENDPOINTS ESPEC√çFICOS PARA SISTEMA IA AVANZADO
# ============================================================================

@app.get("/api/v1/ai/models/status",
         summary="Estado de Modelos IA",
         description="Estado detallado de todos los modelos IA",
         tags=["models"])
async def ai_models_status():
    """
    Obtiene estado detallado de todos los modelos IA.
    
    Returns:
        Dict: Estado de cada modelo
    """
    try:
        ai_sys = get_ai_system()
        system_info = ai_sys.get_model_info()
        
        return {
            "models_status": system_info.get("model_details", {}),
            "capabilities_coverage": system_info.get("capabilities_coverage", {}),
            "total_models": system_info.get("total_models", 0),
            "loaded_models": system_info.get("loaded_models", 0),
            "system_ready": True,
            "timestamp": time.time()
        }
    except Exception as e:
        return {
            "error": "ai_system_unavailable",
            "message": str(e),
            "system_ready": False,
            "timestamp": time.time()
        }

@app.get("/api/v1/ai/capabilities",
         summary="Capacidades del Sistema IA",
         description="Lista completa de capacidades del sistema IA",
         tags=["capabilities"])
async def ai_capabilities():
    """
    Obtiene lista completa de capacidades del sistema IA.
    
    Returns:
        Dict: Capacidades disponibles
    """
    try:
        ai_sys = get_ai_system()
        system_info = ai_sys.get_model_info()
        
        return {
            "capabilities": system_info.get("capabilities", {}),
            "advanced_features": system_info.get("advanced_features", []),
            "pathologies_supported": system_info.get("pathologies_supported", "Variable"),
            "system_type": system_info.get("system_type", "Unknown"),
            "timestamp": time.time()
        }
    except Exception as e:
        return {
            "error": "ai_system_unavailable",
            "message": str(e),
            "capabilities": {},
            "timestamp": time.time()
        }

# ============================================================================
# FUNCI√ìN PRINCIPAL PARA EJECUTAR LA APLICACI√ìN
# ============================================================================

if __name__ == "__main__":
    logger.info("üöÄ Iniciando API Backend Avanzado para Liferay...")
    
    uvicorn_config = {
        "app": "app.main:app",
        "host": settings.host,
        "port": settings.port,
        "reload": settings.debug,
        "log_level": settings.log_level.lower(),
        "access_log": True
    }
    
    if not settings.debug:
        uvicorn_config.update({
            "workers": settings.workers,
            "reload": False
        })
    
    # Informaci√≥n de endpoints
    logger.info(f"üåê API disponible en: http://{settings.host}:{settings.port}")
    logger.info(f"üß† Endpoint ensemble: http://{settings.host}:{settings.port}/api/v1/analysis/upload")
    logger.info(f"üè• Endpoint modelo √∫nico: http://{settings.host}:{settings.port}/api/v1/analysis/upload?use_ensemble=false")
    logger.info(f"üìä Health check avanzado: http://{settings.host}:{settings.port}/api/v1/analysis/health")
    logger.info(f"üîç Estado del sistema: http://{settings.host}:{settings.port}/system/status")
    logger.info(f"üìö Documentaci√≥n: http://{settings.host}:{settings.port}/docs")
    
    uvicorn.run(**uvicorn_config)